import streamlit as st
import json
import httpx
import uuid
import os

# FastAPI backend URL
BACKEND_URL = os.getenv("BACKEND_URL", "http://localhost:8001")

st.set_page_config(
    page_title="ì˜ë£Œ QA ì—ì´ì „íŠ¸",
    page_icon="ğŸ¥",
    layout="wide"
)

# Initialize Session ID
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

# Initialize Messages
if "messages" not in st.session_state:
    st.session_state.messages = []

st.title("ğŸ¥ ì˜ë£Œ QA ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ")
st.markdown("""
ì´ ì‹œìŠ¤í…œì€ Upstage Solar LLMê³¼ LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ì¶•ëœ ì˜ë£Œ ì „ë¬¸ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì—ì´ì „íŠ¸ê°€ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
""")

# Sidebar settings
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    if st.button("ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”"):
        st.session_state.messages = []
        st.session_state.session_id = str(uuid.uuid4())
        st.rerun()

# Display chat history
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])


def response_generator(prompt, session_id):
    """
    Connects to the backend and yields chunks of text for st.write_stream.
    """
    try:
        with httpx.stream(
                "POST",
                f"{BACKEND_URL}/agent/chat/stream",
                json={
                    "query": prompt,
                    "session_id": session_id
                },
                timeout=None
        ) as response:
            if response.status_code != 200:
                yield f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ (ìƒíƒœ ì½”ë“œ: {response.status_code})"
                return

            # [ìˆ˜ì •] st.status ê°ì²´ ìƒì„±
            status = st.status("ì—ì´ì „íŠ¸ê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...", expanded=True)

            is_answering = False

            for line in response.iter_lines():
                if line.startswith("data: "):
                    data_str = line[len("data: "):].strip()

                    if data_str == "[DONE]":
                        break

                    try:
                        event = json.loads(data_str)
                        if "error" in event:
                            yield f"\n\n**ì—ëŸ¬ ë°œìƒ**: {event['error']}"
                            break

                        # 1. ë¡œê·¸ ì²˜ë¦¬ (ë³µêµ¬)
                        # Spinner ë‚´ë¶€(status)ì— ì£¼ìš” ë‹¨ê³„ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.
                        if "log" in event:
                            status.write(event['log'])
                            continue

                        # 2. ì¤‘ê°„ ìƒê°(Thought) ì²˜ë¦¬ ë¡œì§ ì œê±°
                        # ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ë°±ì—”ë“œì—ì„œ ë³´ë‚´ì§€ ì•Šìœ¼ë¯€ë¡œ ì²˜ë¦¬ ë¡œì§ë„ ì‚­ì œí•¨

                        # 3. ë‹µë³€(Answer) ì²˜ë¦¬
                        # Spinner ì™¸ë¶€(ë©”ì¸ ì±„íŒ…ì°½)ì— ì‘ì„±ë˜ì–´ì•¼ í•˜ë¯€ë¡œ yieldë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
                        if "answer" in event and event["answer"]:
                            if not is_answering:
                                # ë‹µë³€ ì‹œì‘ ì‹œ Spinner ìƒíƒœ ì—…ë°ì´íŠ¸ (ì ‘ê¸°)
                                status.update(label="ë¶„ì„ ì™„ë£Œ", state="complete", expanded=False)
                                is_answering = True

                            # ì—¬ê¸°ì„œ yieldí•˜ë©´ with status: ë¸”ë¡ ë°–ì´ë¯€ë¡œ
                            # st.write_streamì´ í˜¸ì¶œëœ ìœ„ì¹˜(assistant message)ì— ë°”ë¡œ ì°í™ë‹ˆë‹¤.
                            yield event["answer"]

                    except json.JSONDecodeError:
                        continue

            # ë£¨í”„ê°€ ëë‚  ë•Œê¹Œì§€ answerê°€ ì—†ì—ˆë‹¤ë©´ status ê°•ì œ ì¢…ë£Œ
            if not is_answering:
                status.update(label="ì‘ì—… ì™„ë£Œ", state="complete", expanded=False)

    except Exception as e:
        yield f"ì—°ê²° ì˜¤ë¥˜: {str(e)}"


# User Input handling
if prompt := st.chat_input("ì˜ë£Œ ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."):
    # Add user message to state and display
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Agent response logic
    with st.chat_message("assistant"):
        # st.write_streamì€ generatorì—ì„œ yieldë˜ëŠ” ë‹µë³€ ë¶€ë¶„ë§Œ í™”ë©´ì— ì‹¤ì‹œê°„ìœ¼ë¡œ ê·¸ë¦¼
        full_response = st.write_stream(response_generator(prompt, st.session_state.session_id))

        # Save complete response to session state
        st.session_state.messages.append({
            "role": "assistant",
            "content": full_response
        })

# Footer information
st.markdown("---")
st.caption("Powered by Upstage Solar LLM & LangGraph")
